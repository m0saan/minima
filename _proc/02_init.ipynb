{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: The `init` module in the `minima` (mi) library provides a suite of tensor\n",
    "  initialization functions to create and initialize tensors in various ways. Each\n",
    "  function in this module represents a different strategy for initializing the values\n",
    "  of a tensor, such as uniform or normal random values, constant values, or specialized\n",
    "  initializations like Xavier or Kaiming methods.\n",
    "output-file: init.html\n",
    "title: init\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974276f8-0ba7-49fb-94e6-d2adae691c36",
   "metadata": {},
   "source": [
    "1. **[`rand`](https://m0saan.github.io/minima/init.html#rand)**: This function generates a tensor filled with random numbers drawn from a uniform distribution between `low` and `high` (defaulting to 0 and 1). It does this by creating an array of random values on the specified device (defaulting to CPU), then scales and shifts these values to the correct range. The result is wrapped in a `mi.Tensor` object, which supports automatic differentiation if `requires_grad` is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L12){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### rand\n",
       "\n",
       ">      rand (*shape, low=0.0, high=1.0, device=None, dtype='float32',\n",
       ">            requires_grad=False)\n",
       "\n",
       "Generates a tensor with random numbers uniformly distributed between `low` and `high`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| low | float | 0.0 |  |\n",
       "| high | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with random numbers from the uniform distribution between `low` and `high`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L12){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### rand\n",
       "\n",
       ">      rand (*shape, low=0.0, high=1.0, device=None, dtype='float32',\n",
       ">            requires_grad=False)\n",
       "\n",
       "Generates a tensor with random numbers uniformly distributed between `low` and `high`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| low | float | 0.0 |  |\n",
       "| high | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with random numbers from the uniform distribution between `low` and `high`.** |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b68976-7696-43bf-b0ca-f7935eda9331",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minima.Tensor([[0.8361942  0.7891384  0.10970007 0.5923745  0.22967269]\n",
       " [0.61836874 0.12242746 0.89674276 0.26497158 0.25622988]\n",
       " [0.8375568  0.04936132 0.21718413 0.15642066 0.10232401]\n",
       " [0.1440296  0.13674147 0.40588015 0.33155832 0.28403464]\n",
       " [0.58986247 0.20638846 0.24636365 0.75810486 0.94382447]\n",
       " [0.74609196 0.00459267 0.48561355 0.20537768 0.17416522]\n",
       " [0.24115583 0.06162176 0.3904394  0.9618843  0.8685511 ]\n",
       " [0.42657614 0.42485094 0.19993785 0.9789261  0.9477727 ]\n",
       " [0.02524497 0.48020166 0.7375612  0.7842982  0.92582405]\n",
       " [0.12680373 0.41048595 0.00874551 0.16642605 0.39158627]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b739cc-e625-4160-ae41-022effe3c565",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "t = rand(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7790c-bd97-454b-8bb0-a1fdc94f7144",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), minima.cpu(), False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype, t.device, t.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec7bc6-86c7-436a-808f-35de5f94509d",
   "metadata": {},
   "source": [
    "2. **[`randn`](https://m0saan.github.io/minima/init.html#randn)**: Similar to [`rand`](https://m0saan.github.io/minima/init.html#rand), but generates numbers from a normal distribution with the specified mean and standard deviation (defaulting to 0 and 1). This is done by creating an array of normally-distributed random values, then scaling and shifting them to match the requested parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### randn\n",
       "\n",
       ">      randn (*shape, mean=0.0, std=1.0, device=None, dtype='float32',\n",
       ">             requires_grad=False)\n",
       "\n",
       "Generates a tensor with random numbers normally distributed with specified mean and standard deviation.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| mean | float | 0.0 |  |\n",
       "| std | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with random numbers from the normal distribution with the specified mean and standard deviation.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### randn\n",
       "\n",
       ">      randn (*shape, mean=0.0, std=1.0, device=None, dtype='float32',\n",
       ">             requires_grad=False)\n",
       "\n",
       "Generates a tensor with random numbers normally distributed with specified mean and standard deviation.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| mean | float | 0.0 |  |\n",
       "| std | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with random numbers from the normal distribution with the specified mean and standard deviation.** |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(randn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fc7c1-1628-4368-8e9b-d0cf22e9c00f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "t = randn(5,5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69baef10-0dfe-43d8-b999-9e58ac9d619f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minima.Tensor([[ 1.3397974   0.64010125 -0.9311074   0.6728155  -0.1192577 ]\n",
       " [ 0.7008655  -0.7104067  -0.89565736 -0.8261754   0.72841895]\n",
       " [-0.8426411  -0.8788722  -0.661193   -1.4981922   0.15918176]\n",
       " [ 0.9665735  -1.2228402   0.7100398   0.4944528   0.34494334]\n",
       " [-0.22832021  0.5712975   1.866018   -0.6395092   0.90164375]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d6791-37d8-4b0f-addc-8947697af949",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 5), dtype('float32'), minima.cpu(), True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, t.dtype, t.device, t.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1a3e9-0427-49bc-96cc-bea58ea00f05",
   "metadata": {},
   "source": [
    "3. **[`constant`](https://m0saan.github.io/minima/init.html#constant)**: This function creates a tensor filled with a constant value `c` (defaulting to 1). It does this by creating an array of ones on the specified device and then scaling these ones by the constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L74){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### constant\n",
       "\n",
       ">      constant (*shape, c=1.0, device=None, dtype='float32',\n",
       ">                requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with a constant value.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| c | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with the constant value `c`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L74){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### constant\n",
       "\n",
       ">      constant (*shape, c=1.0, device=None, dtype='float32',\n",
       ">                requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with a constant value.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| c | float | 1.0 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with the constant value `c`.** |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066880d-8dd1-44fc-a734-23384d48f511",
   "metadata": {},
   "source": [
    "4. **[`ones`](https://m0saan.github.io/minima/init.html#ones) and [`zeros`](https://m0saan.github.io/minima/init.html#zeros)**: These functions are simply shortcuts for creating tensors filled with ones or zeros, respectively. They're implemented by calling the [`constant`](https://m0saan.github.io/minima/init.html#constant) function with `c` set to 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ones\n",
       "\n",
       ">      ones (*shape, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with ones.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with ones.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ones\n",
       "\n",
       ">      ones (*shape, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with ones.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with ones.** |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### zeros\n",
       "\n",
       ">      zeros (*shape, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with zeros.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with zeros.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### zeros\n",
       "\n",
       ">      zeros (*shape, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a tensor filled with zeros.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | float32 |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape `shape`, filled with zeros.** |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cedbc9-465b-4cf0-9808-73d7a85b939f",
   "metadata": {},
   "source": [
    "5. **[`randb`](https://m0saan.github.io/minima/init.html#randb)**: This function creates a binary tensor, with each element independently being True with probability `p` (defaulting to 0.5). This is done by generating uniformly-distributed random numbers and checking whether they're less than or equal to `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L150){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### randb\n",
       "\n",
       ">      randb (*shape, p=0.5, device=None, dtype='bool', requires_grad=False)\n",
       "\n",
       "Generates a binary tensor with random values of `True` or `False`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| p | float | 0.5 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | bool |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A binary tensor of shape `shape`, filled with random boolean values, where the probability of `True` is `p`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L150){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### randb\n",
       "\n",
       ">      randb (*shape, p=0.5, device=None, dtype='bool', requires_grad=False)\n",
       "\n",
       "Generates a binary tensor with random values of `True` or `False`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| shape |  |  |  |\n",
       "| p | float | 0.5 |  |\n",
       "| device | NoneType | None |  |\n",
       "| dtype | str | bool |  |\n",
       "| requires_grad | bool | False |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A binary tensor of shape `shape`, filled with random boolean values, where the probability of `True` is `p`.** |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(randb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65449aee-3c32-4e7e-b05f-e168788aee75",
   "metadata": {},
   "source": [
    "6. **[`one_hot`](https://m0saan.github.io/minima/init.html#one_hot)**: This function creates a one-hot encoding tensor. Given a size `n` and an index `i`, it creates a tensor of size `n` with a 1 at the `i`-th position and 0s elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L178){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### one_hot\n",
       "\n",
       ">      one_hot (n, i, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a one-hot encoding tensor.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n | int |  | The size of the one-hot vector. |\n",
       "| i | int |  | The index to be set to `1` in the one-hot vector. |\n",
       "| device | NoneType | None | The device where the tensor will be allocated. Default is CPU. |\n",
       "| dtype | str | float32 | The data type of the tensor. Default is 'float32'. |\n",
       "| requires_grad | bool | False | If True, the tensor is created with gradient tracking. Default is False. |\n",
       "| **Returns** | **mi.Tensor** |  | **A one-hot tensor of size `n`, with the `i`th element set to `1` and all others set to `0`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L178){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### one_hot\n",
       "\n",
       ">      one_hot (n, i, device=None, dtype='float32', requires_grad=False)\n",
       "\n",
       "Generates a one-hot encoding tensor.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n | int |  | The size of the one-hot vector. |\n",
       "| i | int |  | The index to be set to `1` in the one-hot vector. |\n",
       "| device | NoneType | None | The device where the tensor will be allocated. Default is CPU. |\n",
       "| dtype | str | float32 | The data type of the tensor. Default is 'float32'. |\n",
       "| requires_grad | bool | False | If True, the tensor is created with gradient tracking. Default is False. |\n",
       "| **Returns** | **mi.Tensor** |  | **A one-hot tensor of size `n`, with the `i`th element set to `1` and all others set to `0`.** |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068d9d1-0d91-4988-a473-2bb2280c73c6",
   "metadata": {},
   "source": [
    "### Glorot/Xavier Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae412a-f9ba-4759-b218-68b10474de14",
   "metadata": {},
   "source": [
    "Xavier initialization, also known as Glorot initialization, is a technique for initializing the weights in artificial neural networks to improve the stability and speed of neural network training. In the paper Understanding the difficulty of training deep feedforward neural networks, researchers identified a value for the variance of the weights that works well to mitigate the problems we've discussed.\n",
    "\n",
    "Here's a high-level idea of how it works:\n",
    "\n",
    "Neural networks are trained using a method called backpropagation, which involves iteratively adjusting the weights of the network based on the difference between the network's current output and its desired output.\n",
    "\n",
    "One challenge with this process is that the scale of the initial weights can have a large impact on the network's learning dynamics. If the weights are too large or too small, the network might learn very slowly, or not at all. This is particularly an issue in deep networks where there are many layers of weights to learn.\n",
    "\n",
    "Xavier initialization seeks to address this issue by scaling the initial weights in proportion to the number of inputs and outputs of the neuron. Specifically, in Xavier initialization, the weights are drawn from a distribution with zero a mean of 0 and a variance defined as: \n",
    "\n",
    "$$\n",
    "\\text{var}(w)=\\frac{2}{n_{in}+n_{out}}\n",
    "$$\n",
    "\n",
    "where $n_{in}$ is the number of inputs to the neuron and $n_{out}$ is the number of outputs. In order to induce the weights to acquire a standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$, consequently causing a variance of $\\frac{2}{n_{in}+n_{out}}$, the weights are initially produced randomly from a normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Subsequently, every weight is multiplied by $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$, effectively shifting the standard deviation of the distribution to $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.\n",
    "\n",
    "![Xavier initialization from a normal distribution](../assets/10.xav-init-normal.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L205){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### xavier_normal\n",
       "\n",
       ">      xavier_normal (fan_in, fan_out, gain=1.0, **kwargs)\n",
       "\n",
       "Initializes a tensor using Xavier (Glorot) Normal initialization.\n",
       "\n",
       "This initializer is designed to keep the scale of the gradients roughly the same\n",
       "in all layers. It samples weights from a normal distribution centered around 0 with \n",
       "standard deviation `gain * sqrt(2 / (fan_in + fan_out))`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | The number of input units in the weight tensor. |\n",
       "| fan_out | int |  | The number of output units in the weight tensor. |\n",
       "| gain | float | 1.0 | Scaling factor for the standard deviation of the normal distribution. Default is 1.0. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor initialized using Xavier Normal initialization.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L205){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### xavier_normal\n",
       "\n",
       ">      xavier_normal (fan_in, fan_out, gain=1.0, **kwargs)\n",
       "\n",
       "Initializes a tensor using Xavier (Glorot) Normal initialization.\n",
       "\n",
       "This initializer is designed to keep the scale of the gradients roughly the same\n",
       "in all layers. It samples weights from a normal distribution centered around 0 with \n",
       "standard deviation `gain * sqrt(2 / (fan_in + fan_out))`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | The number of input units in the weight tensor. |\n",
       "| fan_out | int |  | The number of output units in the weight tensor. |\n",
       "| gain | float | 1.0 | Scaling factor for the standard deviation of the normal distribution. Default is 1.0. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor initialized using Xavier Normal initialization.** |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(xavier_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbc42b-b13f-4168-9f84-6204076ab210",
   "metadata": {},
   "source": [
    "It's worth noting that there is also a Xavier initialization variant suitable for uniform distributions as opposed to normal distributions. The resultant weight matrix will comprise values sampled from a uniform distribution within the scope of $(-a, a)$, with $a$ equalling $\\sqrt{\\frac{6}{n_{in}+n_{out}}}$.\n",
    "\n",
    "![Xavier initialization from a uniform distribution](../assets/11.xav-uniform.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L238){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### xavier_uniform\n",
       "\n",
       ">      xavier_uniform (fan_in, fan_out, gain=1.0, **kwargs)\n",
       "\n",
       "Initializes a tensor using Xavier (Glorot) Uniform initialization.\n",
       "\n",
       "This initializer is designed to keep the scale of the gradients roughly the same\n",
       "in all layers. It samples weights from a uniform distribution within the range \n",
       "`[-gain * sqrt(6 / (fan_in + fan_out)), gain * sqrt(6 / (fan_in + fan_out))]`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | The number of input units in the weight tensor. |\n",
       "| fan_out | int |  | The number of output units in the weight tensor. |\n",
       "| gain | float | 1.0 | Scaling factor for the range of the uniform distribution. Default is 1.0. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor initialized using Xavier Uniform initialization.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L238){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### xavier_uniform\n",
       "\n",
       ">      xavier_uniform (fan_in, fan_out, gain=1.0, **kwargs)\n",
       "\n",
       "Initializes a tensor using Xavier (Glorot) Uniform initialization.\n",
       "\n",
       "This initializer is designed to keep the scale of the gradients roughly the same\n",
       "in all layers. It samples weights from a uniform distribution within the range \n",
       "`[-gain * sqrt(6 / (fan_in + fan_out)), gain * sqrt(6 / (fan_in + fan_out))]`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | The number of input units in the weight tensor. |\n",
       "| fan_out | int |  | The number of output units in the weight tensor. |\n",
       "| gain | float | 1.0 | Scaling factor for the range of the uniform distribution. Default is 1.0. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor initialized using Xavier Uniform initialization.** |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(xavier_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2b0a4-ae23-422f-a69d-1b2e61b3577f",
   "metadata": {},
   "source": [
    "Both normal and uniform distributions have demonstrated effectiveness in practical applications, and it is up to the network designer to select the preferred method. Xavier initialization is frequently utilized in practical scenarios to promote more stable training and circumvent issues that stem from unstable gradients, such as the vanishing and exploding gradient predicaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04de89-8310-4c26-83d3-dbc3a3869e63",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Initialize weights with Xavier/Glorot initialization\n",
    "W = xavier_uniform(fan_in=10, fan_out=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d2073-07e0-4e88-8f9c-2ff7563c1f67",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minima.Tensor([[-0.1622775   0.4536291   0.61989725 -0.02014413 -0.05646893]\n",
       " [ 0.5858742   0.46239555  0.20997366  0.46705866  0.23186018]\n",
       " [-0.24604936  0.06220854  0.6072554  -0.05731776  0.5148139 ]\n",
       " [-0.0666193  -0.3852586   0.03337919  0.5635869   0.5360037 ]\n",
       " [-0.36881718  0.4481966  -0.5299952  -0.16656235 -0.63166136]\n",
       " [ 0.06658348 -0.02263997  0.3014384  -0.15522511  0.3325003 ]\n",
       " [-0.12717669 -0.02845087 -0.36774656  0.41525584 -0.46239212]\n",
       " [-0.5931512  -0.541313   -0.5024823   0.2106733   0.14501753]\n",
       " [-0.38586646 -0.3023581   0.2594077   0.27719358 -0.1911264 ]\n",
       " [-0.3176814   0.59976697  0.60364455  0.07043133  0.21091662]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22961e7d-414e-4287-b5be-b6c62c870ba2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "W = xavier_normal(fan_in=10, fan_out=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572ebce-3093-4421-ad12-e37c8260dcc0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minima.Tensor([[ 0.03059636  0.40731347  0.04486648 -0.20211084 -0.2908123 ]\n",
       " [-0.07282545 -0.03428365  0.31833392  0.10940555  0.05456669]\n",
       " [-0.35267887  0.58239627  0.20920038 -0.05054335  0.06172116]\n",
       " [ 0.1331309   0.284902    0.15670004  0.22623208 -0.6965369 ]\n",
       " [ 0.43259475  0.42572162 -0.40264252 -0.43965283  0.46393195]\n",
       " [ 0.710218   -0.02606277 -0.06617628 -0.9257728   0.3177419 ]\n",
       " [-0.03474366 -0.42733535  0.5783244   0.29713896 -0.16121665]\n",
       " [ 0.7878572  -0.01783044  0.23402494  0.20502235 -0.6642037 ]\n",
       " [-0.08082991 -0.18710302  0.13123396  0.42042506  0.17879266]\n",
       " [ 0.15647691  0.3683187  -0.15457386 -0.51149946 -0.7011396 ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30772e1d-bd7b-4200-bf2b-30bc439fa653",
   "metadata": {},
   "source": [
    "The original Xavier initialization was designed for use with the sigmoid activation function, which is symmetric around zero. If you're using a different activation function, like ReLU, you might need a different initialization scheme, like He initialization, which is a modification of Xavier initialization designed for ReLU and other non-symmetric activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6e431-fdc2-4fa8-b4c1-5a3ef5fb7115",
   "metadata": {},
   "source": [
    "### He Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27217d-311f-47f4-afa3-ca6acc160b38",
   "metadata": {},
   "source": [
    "Kaiming Initialization, also known as He Initialization, is a method used in initializing the weights of Neural Networks. This initialization method is designed specifically for neural networks with Rectified Linear Unit (ReLU) activation functions. It was proposed by Kaiming He et al. in their 2015 paper \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\".\n",
    "\n",
    "**Principles of Kaiming Initialization:**\n",
    "\n",
    "The basic idea of Kaiming Initialization is to keep the variance of the input and output of each layer of the neural network as consistent as possible during the forward and backward propagation. This is to solve the problem of gradient dispersion or explosion caused by the deepening of the neural network layer, which can help the model learn effectively.\n",
    "\n",
    "Kaiming initialization initializes a weight matrix $w$ with random values sampled from a normal distribution with mean of $0$ and variance\n",
    "\n",
    "$$\\text{var}(w)=\\frac{2}{n_{i}}$$\n",
    "\n",
    "Here, `n_i` is the number of inputs to the neuron, `w` is the weight vector.\n",
    "\n",
    "Just as with Xavier initialization, to force the weights distribution to take on this variance, the weights ar first randomly generated from a normal distribution with centered around 0 with a standard deviation of 1. Then, each weight is multiplied by \n",
    "\n",
    "$$\\sqrt{\\frac{2}{n_{i}}}$$\n",
    "\n",
    "![Kaiming initialization from a normal distributiont](../assets/12.kaiming-normal.svg)\n",
    "\n",
    "where `n` is the number of inputs coming into a neuron (also known as the \"fan-in\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L271){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### kaiming_normal\n",
       "\n",
       ">      kaiming_normal (fan_in, fan_out, nonlinearity='relu', **kwargs)\n",
       "\n",
       "Fills the input Tensor with values according to the method described in\n",
       "\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al. (2015), using a normal distribution.\n",
       "The resulting tensor will have values sampled from normal distribution with mean=0 and std=sqrt(2 / fan_in).\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | Number of input units in the weight tensor. |\n",
       "| fan_out | int |  | Number of output units in the weight tensor. |\n",
       "| nonlinearity | str | relu | The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape (fan_in, fan_out), filled with random numbers from the normal distribution according to the Kaiming initialization.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L271){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### kaiming_normal\n",
       "\n",
       ">      kaiming_normal (fan_in, fan_out, nonlinearity='relu', **kwargs)\n",
       "\n",
       "Fills the input Tensor with values according to the method described in\n",
       "\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al. (2015), using a normal distribution.\n",
       "The resulting tensor will have values sampled from normal distribution with mean=0 and std=sqrt(2 / fan_in).\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | Number of input units in the weight tensor. |\n",
       "| fan_out | int |  | Number of output units in the weight tensor. |\n",
       "| nonlinearity | str | relu | The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape (fan_in, fan_out), filled with random numbers from the normal distribution according to the Kaiming initialization.** |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(kaiming_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b561b40-a3a0-4419-8af8-3c9ce4c446ed",
   "metadata": {},
   "source": [
    "There is also a version of Kaiming initialization to use for uniform distributions rather than normal distributions. The resulting weight matrix will have values sampled from a uniform distribution within the range $(-a, a)$, where \n",
    "\n",
    "$$a = \\sqrt{\\frac{6}{n_{i}}}$$\n",
    "\n",
    "![Kaiming initialization from a uniform distributiont](../assets/13.kaiming-uniform.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L303){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### kaiming_uniform\n",
       "\n",
       ">      kaiming_uniform (fan_in, fan_out, nonlinearity='relu', **kwargs)\n",
       "\n",
       "Fills the input Tensor with values according to the method described in\n",
       "\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al. (2015), using a uniform distribution.\n",
       "The resulting tensor will have values sampled from uniform distribution in the range [-std, std] where std = sqrt(2 / fan_in).\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | Number of input units in the weight tensor. |\n",
       "| fan_out | int |  | Number of output units in the weight tensor. |\n",
       "| nonlinearity | str | relu | The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape (fan_in, fan_out), filled with random numbers from the uniform distribution according to the Kaiming initialization.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/init.py#L303){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### kaiming_uniform\n",
       "\n",
       ">      kaiming_uniform (fan_in, fan_out, nonlinearity='relu', **kwargs)\n",
       "\n",
       "Fills the input Tensor with values according to the method described in\n",
       "\"Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification\" - He, K. et al. (2015), using a uniform distribution.\n",
       "The resulting tensor will have values sampled from uniform distribution in the range [-std, std] where std = sqrt(2 / fan_in).\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| fan_in | int |  | Number of input units in the weight tensor. |\n",
       "| fan_out | int |  | Number of output units in the weight tensor. |\n",
       "| nonlinearity | str | relu | The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'. |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **mi.Tensor** |  | **A tensor of shape (fan_in, fan_out), filled with random numbers from the uniform distribution according to the Kaiming initialization.** |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(kaiming_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74655c-a66d-471f-8178-4b04b0ee69ad",
   "metadata": {},
   "source": [
    "**Advantages of Kaiming Initialization:**\n",
    "\n",
    "1. It helps to keep the variance of the gradients roughly the same across all layers. This ensures that all layers in the network learn at about the same speed, avoiding the saturation of activation functions, and it can also help speed up the convergence of the network.\n",
    "2. It performs better with ReLU and its variants because it accounts for the fact that the variance of the output of a neuron with a ReLU activation function is half the variance of its input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db18cd9-190f-4103-9866-6e7fe7f4863a",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1dfee-dfdd-402c-ba30-997ddeab9776",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
