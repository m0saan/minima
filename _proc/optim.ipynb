{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a9cd39fb",
   "metadata": {},
   "source": [
    "---\n",
    "description: Fill in a module description here\n",
    "output-file: optim.html\n",
    "title: optim\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fb2ba",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fea54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (params)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Optimizer\n",
       "\n",
       ">      Optimizer (params)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGD\n",
       "\n",
       ">      SGD (params, lr=0.01, momentum=0.0, wd=0.0)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGD\n",
       "\n",
       ">      SGD (params, lr=0.01, momentum=0.0, wd=0.0)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa00356-7cb1-4aa3-9bf6-70e5967cd2a3",
   "metadata": {},
   "source": [
    "## Adam Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a810ab-455b-41a8-bba0-edb974d39f4d",
   "metadata": {},
   "source": [
    "This is a [PyTorch](https://pytorch.org) implementation of popular optimizer *Adam* from paper\n",
    " [Adam: A Method for Stochastic Optimization](https://papers.labml.ai/paper/1412.6980).\n",
    "\n",
    "*Adam* update is,\n",
    "$$\n",
    "\\begin{align}\n",
    "m_t &\\leftarrow \\beta_1 m_{t-1} + (1 - \\beta_1) \\cdot g_t \\\\\n",
    "v_t &\\leftarrow \\beta_2 v_{t-1} + (1 - \\beta_2) \\cdot g_t^2 \\\\\n",
    "\\hat{m}_t &\\leftarrow \\frac{m_t}{1-\\beta_1^t} \\\\\n",
    "\\hat{v}_t &\\leftarrow \\frac{v_t}{1-\\beta_2^t} \\\\\n",
    "\\theta_t &\\leftarrow \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\alpha$, $\\beta_1$, $\\beta_2$ and $\\epsilon$ are scalar hyper parameters.\n",
    "$m_t$ and $v_t$ are first and second order moments.\n",
    "$\\hat{m}_t$  and $\\hat{v}_t$ are biased corrected moments.\n",
    "$\\epsilon$ is used as a fix for division by zero error, but also acts as a form of a hyper-parameter\n",
    "that acts against variance in gradients.\n",
    "\n",
    "Effective step taken assuming $\\epsilon = 0$ is,\n",
    "$$\\Delta t = \\alpha \\cdot \\frac{\\hat{m}_t}{\\hat{v}_t}$$\n",
    "This is bounded by,\n",
    "$$\\vert \\Delta t \\vert \\le \\alpha \\cdot \\frac{1 - \\beta_1}{\\sqrt{1-\\beta_2}}$$\n",
    "when $1-\\beta_1 \\gt \\sqrt{1-\\beta_2}$\n",
    "and\n",
    "$$\\vert \\Delta t\\vert  \\le \\alpha$$\n",
    "otherwise.\n",
    "And in most common scenarios,\n",
    "$$\\vert \\Delta t \\vert \\approx \\alpha$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4527523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L61){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Adam\n",
       "\n",
       ">      Adam (params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-08,\n",
       ">            weight_decay=0.0)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params |  |  | `params` is the list of parameters |\n",
       "| lr | float | 0.01 | `lr` is the learning rate $\\alpha$ |\n",
       "| beta1 | float | 0.9 |  |\n",
       "| beta2 | float | 0.999 |  |\n",
       "| eps | float | 1e-08 | `eps` is $\\hat{\\epsilon}$ or $\\epsilon$ based on `optimized_update` |\n",
       "| weight_decay | float | 0.0 | is an instance of class `WeightDecay` defined in [`__init__.py`](index.html) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/m0saan/minima/blob/main/minima/optim.py#L61){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Adam\n",
       "\n",
       ">      Adam (params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-08,\n",
       ">            weight_decay=0.0)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params |  |  | `params` is the list of parameters |\n",
       "| lr | float | 0.01 | `lr` is the learning rate $\\alpha$ |\n",
       "| beta1 | float | 0.9 |  |\n",
       "| beta2 | float | 0.999 |  |\n",
       "| eps | float | 1e-08 | `eps` is $\\hat{\\epsilon}$ or $\\epsilon$ based on `optimized_update` |\n",
       "| weight_decay | float | 0.0 | is an instance of class `WeightDecay` defined in [`__init__.py`](index.html) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea53c25-e2b7-47a0-ac9d-161213193c18",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2943be0-3cdf-4622-9421-9b1405b18bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae20858-2009-470d-a863-ac0bd45ed6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
