# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_init.ipynb.

# %% auto 0
__all__ = ['rand', 'randn', 'constant', 'ones', 'zeros', 'randb', 'one_hot', 'xavier_normal', 'xavier_uniform', 'kaiming_normal',
           'kaiming_uniform']

# %% ../nbs/02_init.ipynb 2
import math
import minima as mi
from functools import partial

# %% ../nbs/02_init.ipynb 4
def rand(
    *shape, # The shape of the output tensor. Variable length argument list. 
    low=0.0, # Lower bound of the uniform distribution. Default is 0.0.
    high=1.0, # Upper bound of the uniform distribution. Default is 1.0.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype='float32', # The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a tensor with random numbers uniformly distributed between `low` and `high`.

    Parameters
    ----------
    *shape : int
    low : float, optional
    high : float, optional
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A tensor of shape `shape`, filled with random numbers from the uniform distribution between `low` and `high`.

    """
    device = mi.default_device() if device is None else device
    array = device.rand(*shape, dtype=dtype) * (high - low) + low
    print(type(array))
    return mi.Tensor(array, device=device, dtype=dtype, requires_grad=requires_grad)


# %% ../nbs/02_init.ipynb 9
def randn(
    *shape, # The shape of the output tensor. Variable length argument list.
    mean=0.0,# Mean of the normal distribution. Default is 0.0.
    std=1.0, # Standard deviation of the normal distribution. Default is 1.0.
    device=None,# The device where the tensor will be allocated. Default is CPU.
    dtype="float32",# The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a tensor with random numbers normally distributed with specified mean and standard deviation.

    Parameters
    ----------
    *shape : int
    mean : float, optional
    std : float, optional
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A tensor of shape `shape`, filled with random numbers from the normal distribution with the specified mean and standard deviation.
    """
    device = ndl.default_device() if device is None else device
    array = device.randn(*shape, dtype=dtype) * std + mean
    return mi.Tensor(array, device=device, dtype=dtype, requires_grad=requires_grad)

# %% ../nbs/02_init.ipynb 14
def constant(
    *shape, # The shape of the output tensor. Variable length argument list.
    c=1.0, # The constant value to fill the tensor with. Default is 1.0.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype="float32", # The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a tensor filled with a constant value.

    Parameters
    ----------
    *shape : int
    c : float, optional
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A tensor of shape `shape`, filled with the constant value `c`.
    """
    device = mi.default_device() if device is None else device
    array = device.full(shape, c, dtype=dtype)
    return mi.Tensor(array, device=device, dtype=dtype, requires_grad=requires_grad)

# %% ../nbs/02_init.ipynb 16
def ones(
    *shape, # The shape of the output tensor. Variable length argument list.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype="float32", # The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a tensor filled with ones.

    Parameters
    ----------
    *shape : int
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A tensor of shape `shape`, filled with ones.
    """
    return constant(*shape, c=1.0, device=device, dtype=dtype, requires_grad=requires_grad)

# %% ../nbs/02_init.ipynb 17
def zeros(
    *shape, # The shape of the output tensor. Variable length argument list.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype="float32", # The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a tensor filled with zeros.

    Parameters
    ----------
    *shape : int
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A tensor of shape `shape`, filled with zeros.
    """
    return constant(*shape, c=0.0, device=device, dtype=dtype, requires_grad=requires_grad)

# %% ../nbs/02_init.ipynb 19
def randb(
    *shape, # The shape of the output tensor. Variable length argument list.
    p=0.5, # The probability of generating a `True` (1) in the binary tensor. Default is 0.5.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype="bool", # The data type of the tensor. Default is 'bool'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a binary tensor with random values of `True` or `False`.

    Parameters
    ----------
    *shape : int
    p : float, optional
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A binary tensor of shape `shape`, filled with random boolean values, where the probability of `True` is `p`.
    """
    device = mi.default_device() if device is None else device
    array = device.rand(*shape) <= p
    return mi.Tensor(array, device=device, dtype=dtype, requires_grad=requires_grad)

# %% ../nbs/02_init.ipynb 21
def one_hot(
    n, # The size of the one-hot vector.
    i, # The index to be set to `1` in the one-hot vector.
    device=None, # The device where the tensor will be allocated. Default is CPU.
    dtype="float32", # The data type of the tensor. Default is 'float32'.
    requires_grad=False # If True, the tensor is created with gradient tracking. Default is False.
):
    """
    Generates a one-hot encoding tensor.

    Parameters
    ----------
    n : int
    i : int
    device : Device, optional
    dtype : str, optional
    requires_grad : bool, optional
    
    Returns
    -------
    mi.Tensor
        A one-hot tensor of size `n`, with the `i`th element set to `1` and all others set to `0`.
    """
    device = mi.default_device() if device is None else device
    return ndl.Tensor(
        device.one_hot(n, i.numpy().astype("int32"), dtype=dtype),
        device=device,
        requires_grad=requires_grad,
    )

# %% ../nbs/02_init.ipynb 25
def xavier_normal(
    fan_in, # The number of input units in the weight tensor.
    fan_out, # The number of output units in the weight tensor.
    gain=1.0, # Scaling factor for the standard deviation of the normal distribution. Default is 1.0.
    **kwargs # Additional arguments.
):
    """
    Initializes a tensor using Xavier (Glorot) Normal initialization.

    This initializer is designed to keep the scale of the gradients roughly the same
    in all layers. It samples weights from a normal distribution centered around 0 with 
    standard deviation `gain * sqrt(2 / (fan_in + fan_out))`

    Parameters
    ----------
    fan_in : int
        The number of input units in the weight tensor.
    fan_out : int
        The number of output units in the weight tensor.
    gain : float, optional
        Scaling factor for the standard deviation of the normal distribution. Default is 1.0.
    **kwargs
        Additional arguments.
    
    Returns
    -------
    mi.Tensor
        A tensor initialized using Xavier Normal initialization.
    """
    std = gain * math.sqrt(2 / (fan_in + fan_out))
    return randn(fan_in, fan_out) * std

# %% ../nbs/02_init.ipynb 27
def xavier_uniform(
    fan_in, # The number of input units in the weight tensor.
    fan_out, # The number of output units in the weight tensor.
    gain=1.0, # Scaling factor for the range of the uniform distribution. Default is 1.0.
    **kwargs # Additional arguments.
):
    """
    Initializes a tensor using Xavier (Glorot) Uniform initialization.

    This initializer is designed to keep the scale of the gradients roughly the same
    in all layers. It samples weights from a uniform distribution within the range 
    `[-gain * sqrt(6 / (fan_in + fan_out)), gain * sqrt(6 / (fan_in + fan_out))]`

    Parameters
    ----------
    fan_in : int
        The number of input units in the weight tensor.
    fan_out : int
        The number of output units in the weight tensor.
    gain : float, optional
        Scaling factor for the range of the uniform distribution. Default is 1.0.
    **kwargs
        Additional arguments.
    
    Returns
    -------
    mi.Tensor
        A tensor initialized using Xavier Uniform initialization.
    """
    a = gain * math.sqrt(6 / (fan_in + fan_out))
    return rand(fan_in, fan_out, low=-a, high=a)

# %% ../nbs/02_init.ipynb 36
def kaiming_normal(
    fan_in,  # Number of input units in the weight tensor.
    fan_out, # Number of output units in the weight tensor.
    nonlinearity="relu", # The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'.
    **kwargs # Additional keyword arguments
):
    """
    Fills the input Tensor with values according to the method described in
    "Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification" - He, K. et al. (2015), using a normal distribution.
    The resulting tensor will have values sampled from normal distribution with mean=0 and std=sqrt(2 / fan_in).

    Parameters
    ----------
    fan_in : int
        Number of input units in the weight tensor.
    fan_out : int
        Number of output units in the weight tensor.
    nonlinearity : str, optional
        The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'.
    **kwargs : optional
        Additional keyword arguments.
    
    Returns
    -------
    mi.Tensor
        A tensor of shape (fan_in, fan_out), filled with random numbers from the normal distribution according to the Kaiming initialization.
    """
    assert nonlinearity == "relu", "Only relu supported currently"
    std = np.sqrt(2) / np.sqrt(fan_in)
    return randn(fan_in, fan_out) * std

# %% ../nbs/02_init.ipynb 38
def kaiming_uniform(
    fan_in,  # Number of input units in the weight tensor.
    fan_out, # Number of output units in the weight tensor.
    nonlinearity="relu", # The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'.
    **kwargs # Additional keyword arguments
):
    """
    Fills the input Tensor with values according to the method described in
    "Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification" - He, K. et al. (2015), using a uniform distribution.
    The resulting tensor will have values sampled from uniform distribution in the range [-std, std] where std = sqrt(2 / fan_in).

    Parameters
    ----------
    fan_in : int
        Number of input units in the weight tensor.
    fan_out : int
        Number of output units in the weight tensor.
    nonlinearity : str, optional
        The non-linear function (`nn.functional` name), recommended to use only with 'relu' or 'leaky_relu'. Default is 'relu'.
    **kwargs : optional
        Additional keyword arguments.
    
    Returns
    -------
    mi.Tensor
        A tensor of shape (fan_in, fan_out), filled with random numbers from the uniform distribution according to the Kaiming initialization.
    """
    assert nonlinearity == "relu", "Only relu supported currently"
    gain = math.sqrt(2)
    std = gain * math.sqrt(3/fan_in)
    return rand(fan_in, fan_out, low=-std, high=std)
