{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33695328-8cc1-4882-b927-716255e39a27",
   "metadata": {},
   "source": [
    "# optim\n",
    "\n",
    "> The `Optim` module in minima is a flexible and powerful toolbox for optimizing the parameters of your deep learning models. Built on a high-level,  \n",
    "> intuitive, and pythonic API, it provides several out-of-the-box optimization strategies, such as Stochastic Gradient Descent (SGD), Adam, and more.  \n",
    "> In the heart of this module lies the abstract `Optimizer` class that defines a standard interface for all the optimization strategies.  \n",
    "> Each specific optimizer class implements this interface, which ensures a consistent usage and allows for easy swapping of different strategies in your training loop.  \n",
    "\n",
    "> Among the features of this module are:  \n",
    "> - Efficient gradient computations and updates.  \n",
    "> - Advanced optimization strategies with adaptive learning rates.  \n",
    "> - Easy to extend to custom optimization strategies.  \n",
    "> - Supports weight decay regularization for avoiding overfitting.  \n",
    "\n",
    "> Whether you're training a simple linear regression or a complex deep neural network, `Optim` has got you covered. With its simple and consistent interface, the module makes the task of optimizing your models a breeze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9455d3-bb53-4b0e-8f83-b3c74aea27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1851e7-c0db-432f-8b7e-07c23612d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import minima as mi\n",
    "from minima.nn import Parameter\n",
    "from minima.autograd import Tensor\n",
    "from minima import init\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117a048-d97f-45cb-857e-239ee00bc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    Base class for all optimizers. Not meant to be instantiated directly.\n",
    "\n",
    "    This class represents the abstract concept of an optimizer, and contains methods that \n",
    "    all concrete optimizer classes must implement. It is designed to handle the parameters \n",
    "    of a machine learning model, providing functionality to perform a step of optimization \n",
    "    and to zero out gradients.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : Iterable\n",
    "        The parameters of the model to be optimized.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        If the `step` method is not implemented in a subclass.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params # The parameters of the model to be optimized.\n",
    "    ):\n",
    "        self.params = params\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        This method must be overridden by any subclass to provide the specific optimization logic.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        NotImplementedError\n",
    "            If the method is not implemented in a subclass.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Zeros out all gradients in `params`.\n",
    "\n",
    "        This method is typically used before backpropagation to ensure that gradients \n",
    "        are not being accumulated from multiple passes.\n",
    "        \"\"\"\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408375e-08e1-4eba-ac22-20d04edefc8f",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e3697-2668-4806-992f-8fc1fbb6dd5a",
   "metadata": {},
   "source": [
    "This is a PyTorch-style implementation of the classic optimizer Stochastic Gradient Descent (SGD).\n",
    "\n",
    "SGD update is,\n",
    "\n",
    "$$\n",
    "\\theta_{t} = \\theta_{t-1} - \\alpha \\cdot g_{t}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate, and $g_{t}$ is the gradient at time step $t$. $Î¸_{t}$ represents the model parameters at time step $t$.\n",
    "\n",
    "The learning rate $\\alpha$ is a scalar hyperparameter that controls the size of the update at each iteration.\n",
    "\n",
    "An optional momentum term can be added to the update rule:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "v_{t} & \\leftarrow \\mu v_{t-1} + (1-\\mu) \\cdot g_t \\\\\n",
    "\\theta_{t} & \\leftarrow \\theta_{t-1} - \\alpha \\cdot v_t \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $v_{t}$ is the momentum term at time step $t$, and $\\mu$ is the momentum factor. The momentum term increases for dimensions whose gradients point in the same   \n",
    "direction and reduces updates for dimensions whose gradients change direction, thereby adding a form of preconditioning.  \n",
    "\n",
    "A weight decay term can also be included, which adds a regularization effect:\n",
    "\n",
    "$$\n",
    "\\theta_{t} = (1 - \\alpha \\cdot \\lambda) \\cdot \\theta_{t-1} - \\alpha \\cdot g_t\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the weight decay factor. This results in the model weights shrinking at each time step, which can prevent overfitting by keeping the model complexity in check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b16d1-e0db-4747-92d5-aa4fd533a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SGD(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements stochastic gradient descent (optionally with momentum).\n",
    "\n",
    "    This is a basic optimizer that's suitable for many machine learning models, and is often\n",
    "    used as a baseline for comparing other optimizers' performance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : Iterable\n",
    "        The parameters of the model to be optimized.\n",
    "    lr : float, optional\n",
    "        The learning rate.\n",
    "    momentum : float, optional\n",
    "        The momentum factor.\n",
    "    wd : float, optional\n",
    "        The weight decay (L2 regularization).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params, # The parameters of the model to be optimized.\n",
    "        lr=0.01, # The learning rate.\n",
    "        momentum=0.0, # The momentum factor.\n",
    "        wd=0.0 # The weight decay (L2 regularization).\n",
    "    ):\n",
    "        super().__init__(params)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.u = {}\n",
    "        self.wd = wd\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        This method uses the current gradients to adjust the parameters using stochastic gradient descent.\n",
    "        \"\"\"\n",
    "        for self.idx, p in enumerate(self.params):\n",
    "            self._reg_step(p)\n",
    "            self._opt_step(p)\n",
    "\n",
    "    def _opt_step(self, p):\n",
    "        \"\"\"\n",
    "        Performs the optimization step for a single parameter tensor.\n",
    "\n",
    "        If momentum is set, it applies momentum by using a running average of the previous gradients.\n",
    "        \"\"\"\n",
    "        if self.idx not in self.u:\n",
    "            self.u[self.idx] = init.zeros(*p.shape)\n",
    "        self.u[self.idx] = self.momentum * self.u[self.idx] + (1 - self.momentum) * p.grad.data\n",
    "        p.data = p.data - self.lr * self.u[self.idx]\n",
    "\n",
    "    def _reg_step(self, p):\n",
    "        \"\"\"\n",
    "        Applies weight decay for a single parameter tensor.\n",
    "\n",
    "        This form of L2 regularization can help prevent overfitting.\n",
    "        \"\"\"\n",
    "        if self.wd != 0:\n",
    "            p.data *= (1 - self.lr * self.wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3ebf3-74ef-48d0-8ade-3bb981391d0b",
   "metadata": {},
   "source": [
    "## AdaGrad Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9cddc-a6be-4017-8760-7e9c8f155979",
   "metadata": {},
   "source": [
    ">**Intuitive explanation:**\n",
    "  \n",
    "Imagine you're trying to navigate your way across a complex terrain - like a big mountain with lots of hills, valleys and flat areas.   \n",
    "Your goal is to find the lowest valley. This is much like the problem a neural network faces when it's trying to find the optimal values for its weights - the lowest point in its loss function.\n",
    "\n",
    "You start at a random point on this terrain, which is like initializing your model with random weights. Now, you need to figure out which direction to go in to get to the lowest point.    \n",
    "You can't see the whole terrain at once, but you can look around your current location and see which way is downhill. This is like calculating the gradient of the loss function with respect to the weights.   \n",
    "\n",
    "In a basic gradient descent algorithm, you would just go in the direction of the steepest slope with a fixed step size. But this approach can lead to problems.    \n",
    "What if you're on a steep slope and you take too big of a step? You might overshoot the valley you're trying to get to. Or, what if you're on a flat part of the   \n",
    "terrain and you take too small of a step? You might get stuck and not make much progress.  \n",
    "\n",
    "This is where AdaGrad comes in. AdaGrad is like a smart hiker that adjusts its step size based on the terrain it's currently on.   \n",
    "If it's on a steep slope, it takes smaller steps to avoid overshooting the valley. If it's on a flat area, it takes bigger steps to make faster progress. \n",
    "\n",
    "It does this by keeping track of the sum of the squares of the gradients that it has seen so far (kinda like a memory), and uses this to scale down the step size.   \n",
    "This means that parameters with larger gradients will have their learning rate decreased more, while parameters with smaller gradients will have their learning rate   \n",
    "\n",
    "The neat thing about AdaGrad is that it adjusts the learning rate for each parameter individually, based on what it's learned about the landscape around that parameter.   \n",
    "This can be especially useful when dealing with sparse data, where only a few parameters might be updated frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31fcf6-c3a0-4630-a071-a2abcb975dea",
   "metadata": {},
   "source": [
    "> **Detailed explanation**\n",
    "\n",
    "Building on the foundational concepts of Stochastic Gradient Descent (SGD), we have AdaGrad, an algorithm that introduces an innovative twist to the optimization process.  \n",
    "Unlike traditional SGD that utilizes a single learning rate $\\alpha$ across all parameters, AdaGrad institutes a per-parameter learning rate. The learning rate for AdaGrad is computed as:\n",
    "\n",
    "$$\n",
    "\\theta_{t} = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{G_t + \\epsilon}} \\cdot g_{t}\n",
    "$$\n",
    "\n",
    "where $\\theta_{t}$ represents the model parameters at time step $t$, $\\alpha$ is the initial learning rate, $g_{t}$ is the gradient at time step $t$, $G_{t}$ is a diagonal matrix   \n",
    "where each diagonal element $i, i$ is the sum of the squares of the gradients w.r.t. $\\theta_i$ up to time step $t$, and $\\epsilon$ is a smoothing term to avoid division by zero (usually on the order of $1e-7$).\n",
    "\n",
    "In AdaGrad, each parameter $\\theta_i$ gets its own learning rate, which is inversely proportional to the square root of the sum of the squares of past gradients.  \n",
    "This is the `cache` in the implementation, which holds a history of squared gradients. The greater the sum of the past gradients for a particular parameter, the smaller the learning rate for that parameter.\n",
    "\n",
    "This feature allows AdaGrad to normalize the updates made during training, preventing any single weight from rising too high compared to the others.  \n",
    "This is particularly beneficial when dealing with sparse data, as the less frequently updated parameters are allowed larger updates when they do get updated, thereby effectively utilizing more neurons for training.\n",
    "\n",
    "However, it's important to note that AdaGrad has a tendency to decrease the learning rate quite aggressively due to the constant accumulation of the square of gradients in $G_{t}$.   \n",
    "This can sometimes lead to premature and excessive decay of the learning rate during training, causing the model to stop learning before reaching the optimal point.   \n",
    "This monotonic decrease in the learning rate is one reason AdaGrad is not as widely used, except in some specific applications.\n",
    "\n",
    "To summarize, AdaGrad adds a valuable tool to our optimization toolkit by providing an adaptive learning rate for each individual parameter.  \n",
    "It elegantly solves the problem of learning rate selection and normalization of parameter updates, and while it has some limitations, it's a   \n",
    "powerful concept that has paved the way for further innovations in optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6218dc-a0bc-4d86-97c6-ab4e7628a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AdaGrad(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements AdaGrad optimization algorithm.\n",
    "\n",
    "    AdaGrad is an optimizer with parameter-wise learning rates, which adapts the learning rate\n",
    "    based on how frequently a parameter gets updated during training. It's particularly useful\n",
    "    for sparse data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : Iterable\n",
    "        The parameters of the model to be optimized.\n",
    "    lr : float, optional\n",
    "        The initial learning rate.\n",
    "    wd : float, optional\n",
    "        The weight decay (L2 regularization).\n",
    "    eps : float, optional\n",
    "        A small constant for numerical stability.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,  # The parameters of the model to be optimized.\n",
    "        lr=0.01,  # The initial learning rate.\n",
    "        wd=0.0,  # The weight decay (L2 regularization).\n",
    "        eps=1e-7,  # A small constant for numerical stability.\n",
    "    ):\n",
    "        super().__init__(params)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.cache = {}\n",
    "        self.wd = wd\n",
    "        self.eps = eps\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        This method uses the current gradients to adjust the parameters using AdaGrad algorithm.\n",
    "        \"\"\"\n",
    "        for self.idx, p in enumerate(self.params):\n",
    "            self._reg_step(p)\n",
    "            self._opt_step(p)\n",
    "\n",
    "    def _opt_step(self, p):\n",
    "        \"\"\"\n",
    "        Performs the optimization step for a single parameter tensor.\n",
    "\n",
    "        It computes parameter-wise learning rates and updates the parameters accordingly.\n",
    "        \"\"\"\n",
    "        if self.idx not in self.cache:\n",
    "            self.cache[self.idx] = init.zeros(*p.shape)\n",
    "        self.cache[self.idx] += p.grad.data ** 2\n",
    "        p.data = p.data - (self.lr / (self.cache[self.idx] + self.eps) ** 0.5 ) * p.grad.data\n",
    "\n",
    "    def _reg_step(self, p):\n",
    "        \"\"\"\n",
    "        Applies weight decay for a single parameter tensor.\n",
    "\n",
    "        This form of L2 regularization can help prevent overfitting.\n",
    "        \"\"\"\n",
    "        if self.wd != 0:\n",
    "            p.data *= (1 - self.lr * self.wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188fdcf-2f18-4160-a881-789f38355019",
   "metadata": {},
   "source": [
    "### RMSProp Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74668dab-4ae9-47a5-9df2-47115d4c8eee",
   "metadata": {},
   "source": [
    "RMSProp, short for Root Mean Square Propagation, which is an optimization algorithm that introduces an adaptive learning rate for each parameter in a model. \n",
    "\n",
    "RMSProp introduces an adaptive learning rate for each parameter to tackle different landscapes of the loss function. It does this by maintaining a moving (or 'running') average  \n",
    "of the squared gradients, effectively measuring the scale of recent gradients. This running average, also known as the cache, is calculated as follows:   \n",
    "\n",
    "$$\n",
    "cache_{t} = \\rho \\cdot cache_{t-1} + (1-\\rho) \\cdot (g_{t})^2\n",
    "$$\n",
    "\n",
    "where $\\rho$ is the decay rate that determines how much of the history of squared gradients we retain. This cache term holds a form of \"memory\" of the magnitude of recent gradients, and its contents \"move\" with the data over time. \n",
    "\n",
    "Then, the parameter update rule becomes:\n",
    "\n",
    "$$\n",
    "\\theta_{t} = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{cache_{t} + \\epsilon}} \\cdot g_{t}\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is a small constant for numerical stability, often around $1e-8$. This normalization by the square root of the cache ensures smooth changes in the learning rate and   \n",
    "helps retain the global direction of parameter updates. This adaptivity makes the learning rate changes more resilient to fluctuations in the gradient.    \n",
    "\n",
    "RMSProp introduces a new hyperparameter, $\\rho$, the cache memory decay rate. Given the momentum-like properties of RMSProp, even small gradient updates can have substantial effects    \n",
    "due to the adaptive learning rate updates. As such, the default learning rate often used with RMSProp is smaller, around $0.001$, to ensure stability.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bd752-03e3-4c04-98f8-e9604a51c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RMSProp(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements RMSProp optimization algorithm.\n",
    "\n",
    "    RMSProp is an optimizer with parameter-wise adaptive learning rates, which adapt the learning rate\n",
    "    for each parameter individually, making it suitable for dealing with sparse or multi-scale data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : Iterable\n",
    "        The parameters of the model to be optimized.\n",
    "    lr : float, optional\n",
    "        The initial learning rate.\n",
    "    wd : float, optional\n",
    "        The weight decay (L2 regularization).\n",
    "    eps : float, optional\n",
    "        A small constant for numerical stability.\n",
    "    rho : float, optional\n",
    "        The decay rate for the moving average of squared gradients.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,  # The parameters of the model to be optimized.\n",
    "        lr=0.001,  # The initial learning rate.\n",
    "        wd=0.0,  # The weight decay (L2 regularization).\n",
    "        eps=1e-7,  # A small constant for numerical stability.\n",
    "        rho=0.9, # The decay rate for the moving average of squared gradients.\n",
    "    ):\n",
    "        super().__init__(params)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.cache = {}\n",
    "        self.wd = wd\n",
    "        self.eps = eps\n",
    "        self.rho = rho\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        This method uses the current gradients to adjust the parameters using RMSProp algorithm.\n",
    "        \"\"\"\n",
    "        for self.idx, p in enumerate(self.params):\n",
    "            self._reg_step(p)\n",
    "            self._opt_step(p)\n",
    "\n",
    "    def _opt_step(self, p):\n",
    "        \"\"\"\n",
    "        Performs the optimization step for a single parameter tensor.\n",
    "\n",
    "        It computes parameter-wise learning rates and updates the parameters accordingly.\n",
    "        \"\"\"\n",
    "        if self.idx not in self.cache:\n",
    "            self.cache[self.idx] = init.zeros(*p.shape)\n",
    "        self.cache[self.idx] = self.rho * self.cache[self.idx] + (1 - self.rho) * p.grad.data ** 2\n",
    "        p.data = p.data - (self.lr / (self.cache[self.idx] + self.eps) ** 0.5 ) * p.grad.data\n",
    "\n",
    "    def _reg_step(self, p):\n",
    "        \"\"\"\n",
    "        Applies weight decay for a single parameter tensor.\n",
    "\n",
    "        This form of L2 regularization can help prevent overfitting.\n",
    "        \"\"\"\n",
    "        if self.wd != 0:\n",
    "            p.data *= (1 - self.lr * self.wd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7aa00356-7cb1-4aa3-9bf6-70e5967cd2a3",
   "metadata": {},
   "source": [
    "## Adam Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54a810ab-455b-41a8-bba0-edb974d39f4d",
   "metadata": {},
   "source": [
    "This is a PyTorch-like implementation of popular optimizer *Adam* from paper\n",
    " [Adam: A Method for Stochastic Optimization](https://papers.labml.ai/paper/1412.6980).\n",
    "\n",
    "*Adam* update is,\n",
    "$$\n",
    "\\begin{align}\n",
    "m_t &\\leftarrow \\beta_1 m_{t-1} + (1 - \\beta_1) \\cdot g_t \\\\\n",
    "v_t &\\leftarrow \\beta_2 v_{t-1} + (1 - \\beta_2) \\cdot g_t^2 \\\\\n",
    "\\hat{m}_t &\\leftarrow \\frac{m_t}{1-\\beta_1^t} \\\\\n",
    "\\hat{v}_t &\\leftarrow \\frac{v_t}{1-\\beta_2^t} \\\\\n",
    "\\theta_t &\\leftarrow \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\alpha$, $\\beta_1$, $\\beta_2$ and $\\epsilon$ are scalar hyper parameters.\n",
    "$m_t$ and $v_t$ are first and second order moments.\n",
    "$\\hat{m}_t$  and $\\hat{v}_t$ are biased corrected moments.\n",
    "$\\epsilon$ is used as a fix for division by zero error, but also acts as a form of a hyper-parameter\n",
    "that acts against variance in gradients.\n",
    "\n",
    "Effective step taken assuming $\\epsilon = 0$ is,\n",
    "$$\\Delta t = \\alpha \\cdot \\frac{\\hat{m}_t}{\\hat{v}_t}$$\n",
    "This is bounded by,\n",
    "$$\\vert \\Delta t \\vert \\le \\alpha \\cdot \\frac{1 - \\beta_1}{\\sqrt{1-\\beta_2}}$$\n",
    "when $1-\\beta_1 \\gt \\sqrt{1-\\beta_2}$\n",
    "and\n",
    "$$\\vert \\Delta t\\vert  \\le \\alpha$$\n",
    "otherwise.\n",
    "And in most common scenarios,\n",
    "$$\\vert \\Delta t \\vert \\approx \\alpha$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7b291-fea2-4051-921f-224d99ff8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Adam(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the Adam optimization algorithm.\n",
    "\n",
    "    Adam is an adaptive learning rate optimization algorithm that has been designed specifically for training \n",
    "    deep neural networks. It leverages the power of adaptive learning rates methods to find individual learning \n",
    "    rates for each parameter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : Iterable\n",
    "        The parameters of the model to be optimized.\n",
    "    lr : float, optional\n",
    "        The learning rate. Default is 0.01.\n",
    "    beta1 : float, optional\n",
    "        The exponential decay rate for the first moment estimates. Default is 0.9.\n",
    "    beta2 : float, optional\n",
    "        The exponential decay rate for the second moment estimates. Default is 0.999.\n",
    "    eps : float, optional\n",
    "        A small constant for numerical stability. Default is 1e-8.\n",
    "    weight_decay : float, optional\n",
    "        Weight decay (L2 penalty). Default is 0.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    t : int\n",
    "        The time step for the Adam optimizer.\n",
    "    exp_avg : dict\n",
    "        The dictionary to store the exponential moving average of gradient values.\n",
    "    exp_avg_sq : dict\n",
    "        The dictionary to store the exponential moving average of squared gradient values.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        params, # `params` is the list of parameters\n",
    "        lr=0.01, # `lr` is the learning rate $\\alpha$\n",
    "        beta1=0.9, # The exponential decay rate for the first moment estimates. Default is 0.9.\n",
    "        beta2=0.999, # The exponential decay rate for the second moment estimates. Default is 0.999.\n",
    "        eps=1e-8, # `eps` is $\\hat{\\epsilon}$ or $\\epsilon$ based on `optimized_update`\n",
    "        weight_decay=0.0, # is an instance of class `WeightDecay` defined in [`__init__.py`](index.html)\n",
    "    ):\n",
    "        super().__init__(params)\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.wd = weight_decay\n",
    "        self.t = 0\n",
    "\n",
    "        self.exp_avg = {}\n",
    "        self.exp_avg_sq = {}\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        This method updates the parameters based on the current gradient.\n",
    "        \"\"\"\n",
    "        for self.idx, p in enumerate(self.params):\n",
    "            self._reg_step(p)\n",
    "            self._opt_step(p)\n",
    "\n",
    "    def _opt_step(self, p):\n",
    "        \"\"\"\n",
    "        Performs the optimization step for a single parameter tensor.\n",
    "\n",
    "        The method updates the moving averages of the gradient (m) and the squared gradient (v), and then \n",
    "        computes the bias-corrected estimates of these two variables. These bias-corrected estimates are \n",
    "        then used to update the parameter.\n",
    "        \"\"\"\n",
    "        if self.idx not in self.exp_avg:\n",
    "            self.exp_avg[self.idx] = init.zeros(*p.shape)\n",
    "            self.exp_avg_sq[self.idx] = init.zeros(*p.shape)\n",
    "        \n",
    "        # Update biased first and second moment estimates\n",
    "        self.exp_avg[self.idx] = self.beta1 * self.exp_avg[self.idx] + (1 - self.beta1) * p.grad.data\n",
    "        self.exp_avg_sq[self.idx] = self.beta2 * self.exp_avg_sq[self.idx] + (1 - self.beta2) * p.grad.data**2\n",
    "        \n",
    "        # Compute bias-corrected first and second moment estimates\n",
    "        exp_avg_hat = self.exp_avg[self.idx] / (1 - self.beta1 ** (self.idx + 1))\n",
    "        exp_avg_sq_hat = self.exp_avg_sq[self.idx] / (1 - self.beta2 ** (self.idx + 1))\n",
    "        p.data = p.data - self.lr * exp_avg_hat / (exp_avg_sq_hat ** 0.5 + self.eps)\n",
    "\n",
    "    def _reg_step(self, p):\n",
    "        \"\"\"\n",
    "        Applies weight decay for a single parameter tensor.\n",
    "\n",
    "        This form of L2 regularization can help prevent overfitting. It adjusts the parameter by \n",
    "        a small factor of its current value.\n",
    "        \"\"\"\n",
    "        if self.wd != 0:\n",
    "            p.data *= (1 - self.lr * self.wd)\n",
    "        # all same :3\n",
    "        # p.data *= (1 - self.lr * self.weight_decay)\n",
    "        # p.data = p.data - self.lr * self.weight_decay * p.data\n",
    "        # p.data -= self.lr * self.weight_decay * p.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837fe1b-86db-439a-ba29-1567cc5699e1",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2943be0-3cdf-4622-9421-9b1405b18bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae20858-2009-470d-a863-ac0bd45ed6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
